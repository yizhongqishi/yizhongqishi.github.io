---
layout: post
title: 论文学习笔记4
category: article
---
本篇笔记包含多篇基础性论文的内容和感想<br/>
《Adaptive resource provisioning for read intensive multi-tier applications in the cloud》
时间序列分析以及多项式预测：从用户角度来说，服务器响应时间是应用程序最为重要的质量考量。对于平台服务商来说，能够在SLA中提供最大响应时间的保证是需要对当前服务节点的瓶颈进行启发式预测并在达到阈值之前进行自动调度。被动的瓶颈处理方法有一个好处就是基于历史统计数据进行调度能够避免先验性模型和预部署模型的不准确的缺点。对于扩展服务器使用被动反应的方式，文中所谓启发式实际上就是实时监测每次调整后的状态，然后进行再次的修改，在服务器请求中分为静态请求（调度web服务器）和动态请求（调度web服务器和数据库服务器），如果是静态请求的时间过长，则直接增加web服务器，如果是动态请求时间过长，则检查当前cpu使用率，如果存在cpu使用率过高，则增加web服务器，否则增加数据库服务器。对于收缩服务器，则使用一个基于多项式的预测模型进行预测，然后根据预测值判断是否收缩。注：文中所说的第95百分位的平均响应时间是指所有应用的平局响应时间，从小到大排名在其95％排名的响应时间，然后根据不同的请求事件（静态／动态）来实现响应的调整策略。<br/>
《Autonomic Mix-Aware Provisioning for Non-Stationary Data Center Workloads》
使用kmeans的时间序列分析：单单以前台请求量对服务器进行启发式的调度并不是有效的，主要原因在于请求本身可能是多种类别的（比如长请求和短请求），因为最终的结果是体现在服务器的平均响应时间上，因此我们不难看出不同请求类别的组合实际上对于服务器最终的响应时间是有着不同的影响的。对于k-means聚类不同的请求分类，使用迭代的方式求最优k，并在每次迭代计算群内变异系数（标准差比上均值）和群间变异系数、群内方差和群间方差的比值、群内变异系数和群间变异系数的比值，最优k应当那最小化群内方差、最大化群间方差。实际上群只是把在差值小的请求类别放在一起，这也就会可能造成不同的请求类别使得实际的群的平均服务时间有较大的变化（考虑重尾请求，这种长请求可能由于频率低而被分在一个集合，而这个集合的平均值是对频率变化十分敏感的），作者则为群大小设置最大值，当超过最大值时，则将群拆分成多个大小不超过最大值的群。通过实验可以知道（这个实验是否具有通用性？），当求出最优值k，只需要在每个请求类别的频率变化（探测固定时间段内频率变化）的时候不断计算每个群的服务时间的均值即可，而不需要进行重新分类。<br/>
在实际的运行中，作者将应用中的每层（比如数据库层、web服务层等）看作是一个队列，这个队列执行先进先出规则，而所有队列都满足G/G/1的排队模型（这里的1实际上对应的是一个负载均衡器），而我们对于每个群也求出请求到达速率，按照Kingman's formula，结合着SLA最大响应时间y，我们估测出一台服务器的最大请求到达率，当前总请求到达率和估计值的比值就是当前层所需要的服务器数目。
而触发调度策略更新的情况默认为隔一段时间，同时也保留请求数目波动过大、服务器响应时间变长等明显的变化或者违法SLA的情况来触发更改算法的执行。<br/>
《From Data Center Resource Allocation to Control Theory and Back》基于控制论的启发式强化学习<br/>
自动调整是一种在任何给定时间根据需要自动调整分配给应用程序的资源的方法。核心功能是（i）一个可用的资源池，可以按需提取或释放，（ii）一个控制回路来监视系统，并实时决定是否需要增长或缩小。虽然作者想到需要通过控制回路根据反馈来控制调度策略，具体的方式就是减少运行服务器数量以接近SLA，然后随机化增加来探索新状态，这样的方式减少初期所作的无用功，也提出由于实际上策略生效需要一段时间，并不能让系统对请求的变化过于敏感，但是作者并没有在RL上更近一步提出应当选择什么样的有效特征进行学习以及从时间分析的角度去说明服务时长的变化会造成什么样的影响，并且不难看出，作者的实现环境相对单一，测试应用也较为片面。作者的创新处在于提出通过控制回路实现启发式强化学习，并提出学习的模型并不是唯一的，随着时间的发展是要不断更正该模型的<br/>