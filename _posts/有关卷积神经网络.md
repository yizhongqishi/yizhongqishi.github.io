卷积神经网络：
局部感知是因为图像中每个像素点只是和x*x个周围像素相关

权值共享是将存储权值的空间压缩，避免过拟合，聪明的你想到了，全连接情况下权值共享？那不就是一个神经元了么！

局部感知和权值共享的实际操作就是在图片上滑动扫描，下一层有多少个点就采样多少个扫描点

一个卷积核计算出一个feature map,对应着图像的一个特征模式，多个模式经过池化后喂给神经网络进行训练学习

为什么不用CNN进行趋势或者是数值的预测：

第一，目前这样的回归预测更多的是对于趋势的预测，也就是对于涨、平、落的预测，与其说是“预测”，“分类”或许更加贴近，这也就导致了对于论文实际讨论的环境有着相当的不同；

第二，算法在数据的处理上大体分为两个不同的方向——走势图和数值转为图。其中第一个直接从走势图的角度进行CNN处理，这里有个问题就是虽然看起来与CNN目前处理的环境相当契合，而且确实能够在一定程度上判断出未来的走势，但实际上这个图中的数据矩阵相当稀疏，会大大影响收敛速度。第二个的方式是将所有的值看作是图上的值，这里有两个表达方式，一个是将一条数据看作图的一行，步长为图的行数，这样生成一张通道为1的图进行CNN处理，这个方式的问题是行列数的问题，变换一下就是步长和特征数目的问题，尤其是在特征数目上，最终还是需要进行特征的筛选，特征的选取结果大大影响了训练的质量，并且特征数目并不如步长那样变换灵活，而且实际上CNN处理的图片的像素点数目要比能够选择的到的特征数目多得多，并不适合。而另一种方式就是一条数据代表一个像素点，一行一个时间步，样本数为行数，这样极大方便了“图片”规格的修改，但是在预测上却是一个问题，首先每次预测都只是想当于图上一个像素点的改变，这样的操作无论是理论上还是实际上都违反常规，更实际的一点是，为了未来的一个值（像素点），如何去生成一个图？太繁琐了，开发难度也太大。

综上，并不能够使用CNN进行时间序列的预测。