我的想法：<br/>

---

模糊控制和强化学习的结合应当是在行动的选择上，无论是e-greedy还是还是其他，都只是沿着一条策略进行行动的选择，但是

---

模糊规则的制定

参数的选取

---

matlab上可以使用simulink来进行仿真<br/>
模糊输入量的考虑：误差、误差导数（用来表示误差变化幅度）<br/>
在给出系统设计的时候需要考虑系统的鲁棒性和稳定性——在设计测试实验的时候应当考虑进来<br/>
有关RBF？双曲正切s型？神经模糊控制中后件网络和去模糊化的关系<br/>
使用matlab进行神经模糊控制的实现和普通模糊控制的实现

---

在添加服务器的时候应该主动，释放服务器的时候应当被动释放，

---

我认为，应当对于所有的应用通过聚类算法进行聚类分析，要判断出的是哪些类别的应用一天内的请求变化不大，就比如将每天分成24段，每段内请求量曲线的导数都是在0附近波动，对于这样的应用，使用阈值控制被动控制的方式更加有效；对于有波动，但是波动幅度明显的应用，或者是段内波动不大段间差距明显的应用，采用时间序列分析加排队论预测的方式进行控制；对于波动巨大的应用，则将该应用每天的数据外加这一天本身的属性（比如是否工作日等）使用深度强化学习的方式进行建模。<br/>
那么实际上实现的难点有二：（聚类算法的选择、聚类属性的选择），（深度强化学习算法的实现，数据特征提取）。现在已有的代码基础：未知。<br/>

也就是说，我现在论文关注的重点应该在聚类学习和强化学习与弹性伸缩上

---

对于每天的数据，都应该使用强化学习进行一次模型的学习，并和已有的模型进行比对，或许可以通过聚类的对所有的模型进行二次学习，从而了解是否存在一定时间段，模型的替换有着一定的规律这样，那么我们就能够突破长时间来挖掘知识。就比如，某些应用具有很强的时令性，但是一天内的变化却不大，这样和每天都具有剧烈变化但是每天总体规律不变就形成强烈对比<br/>
通过时间序列分析确实更加真实反映出应用和服务器之间的关系，实际上我在具体实现的时候也应当将时间序列分析和kmeans结合起来，为数据特征分析提供有效的支持。<br/>

---

相比较虚拟机启动的方式，docker容器的启动时间能够在1分钟(?)内实现，而且无论是人工标注还是说通过分类判断出的具有突发流量产生的应用，都可以预先在网关下低温运行几个预备容器，这样进一步省去分配域名或者是让负载均衡重新应用的时间。

---

鲁棒性体现在面对数据噪声(?)的稳定性

---

SVM用来预测：通过历史数据的分类，然后利用分类模型将新的数据打上标签，并不能够回归预测出具体的数值(或许离散的当作标签的数字是可以的）。

---

docker stats api能够有效查询容器内部的性能信息，网关现在能够返回请求时长以及响应时长。但是现在在kafka的信息流入和流出上不能够很好使用。CPU负载，内存、IO读写率

---

kmeans聚类方法中可以使用PCA方法降维减少运算复杂度，而通过协方差矩阵能够很高精度还原数据。

---

对请求时间进行二次平滑，对响应时间一次平滑，时间预测为什么不用LSTM呢？？<br/>
多次指数平滑能够对非随机啊变化之间的关系进行进一步的分解，其实进行多次平滑更多的是在数学公式上进行化简<br/>

三次指数平滑算法可以对同时含有趋势和季节性的时间序列进行预测，该算法是基于一次指数平滑和二次指数平滑算法的。