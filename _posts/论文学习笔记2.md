---
layout: default
title: 论文学习笔记2
category: article
---
《MLscale: A machine learning based application-agnostic autoscalerMLscale: A machine learning based application-agnostic autoscaler》<br/>
这是一篇基于机器学习的黑盒弹性伸缩算法。<br/>
对于工作负载在不同时段变化巨大的线上应用服务，传统的静态资源调配能够降低高负载时性能恶化的现象，但是会造成不必要的资源调配，造成成本和能源的消耗<br/>
而实用弹性伸缩的方式进行资源的调配时，对于资源需求的低估和高估会分别造成服务效果低下和资源浪费（跌落到静态资源调配的方式）。弹性伸缩既可以为了减低能源浪费而面向物理资源，也可以为了减少租用成本面向虚拟资源，但是单一地增加减少某几个节点来适配性能需求的效果并不明显，从而也说明弹性伸缩并不是一件容易的事情<br/>
一般来说，为了更好实现资源的弹性伸缩，需要对应用程序以及系统底层架构的动态变化进行理解，才能够保证调度算法的正确性，但是这样就会造成对于应用程序多样性的支持不够。调度算法同应用程序无关，辅助地进行服务器未来负载的预测。为实现这样的目标，需要进行负载和性能之间关系的探索来成功调度系统，而且准确的预测并不能够应用在所有的应用程序上。<br/>
机器学习已经成为黑盒模型建立的最有前景的手段，而且很多弹性伸缩算法也建立在强化学习方法上，通过历史数据和不断试错来找到最优调度方案，这种方式会在学习阶段造成客观的开销。也有使用线性回归模型的方式进行学习和预测的，但负载和性能之间的关系往往是非线性的。<br/>
文章实现了一个基于机器学习的黑盒模型，首先改模型通过神经网络将观察到的指标和性能指标相关，然后通过回归模型预测假想调度事件的可观测指标并预测出性能指标，从而进行最优调度方案的选取。<br/>
以往基于机器学习方法的模型训练有多项式的线上模型，有使用hadoop负载训练模型进行调度工作的，也有线下训练出模型，需要在日后的使用中定期训练的，作者提出的方式能够线上自学习，切没有多项式训练那么复杂，不过需要专家或模糊逻辑来进行模型的初始化。<br/>
对于RL学习消耗大问题，学习过程中模型效果差，有通过使用排队论的方式将系统初始化管理，然后用RL一遍学习生成模型的，也有通过神经网络减少RL状态空间的。<br/>
前人的工作往往是面向已知应用程序资源需求和已知静态资源之间的调度，而本文作者是在应用程序未知的情况下考虑对于系统资源的线上自动调度，并且是围绕自动调度而进行的。<br/>
ML也被用来调整面向特定应用程序模型的参数。 Iqbal等人 [14]采用多项式回归模型，根据RUBiS Web应用程序接收到的静态和动态请求的数量，对层中的服务器数量进行建模。 Horvath等人 [15]使用回归建模响应时间和（仅）CPU利用率，服务器功率和CPU利用率之间的关系。 这些模型然后用于高能效的应用程序缩放。 Lim等人 [26]采用多变量回归来模拟重新平衡数据对弹性存储的影响。 甘地等人。 [5,27]采用卡尔曼滤波器来估计不容易观察的性能模型的参数。 然而，作者从一个通用的排队论模型开始，然后在线导出参数。 相比之下，MLscale不考虑任何以前的应用程序特定的知识或性能模型。<br/>
我们的重点在于何时以及应该配置多少个应用程序虚拟机。<br/>
神经网络的输入：<br/>

* RR:每秒收到的请求数
* CPU:CPU核心平均利用率 
* inter:每秒产生的中断数量
* CTX:每秒上下文切换次数
* KB:每秒数据量
* PK:每秒收到的报文数目
* KBOUT:每秒发送数量
* PKOUT:每秒发送报文数目<br/>

数据的采集使用的是负载均衡下同类服务节点的平均数据而不是单个应用的数据，从而减少状态空间。（这里之名数据的采集是在线的，但是有个问题是，为什么只是采用单层隐藏层）<br/>
网络的输出RT代表响应时间，（如何和真实的数值匹配？），可以考虑的输出还有尾部响应时间、资源使用量、能耗等<br/>
修改策略以获取不同的数据简单地包括：响应时间阈值的修改、CPU阈值的修改、请求速率的修改<br/>

我们还将神经网络与可用于性能建模的其他ML技术进行比较。具体而言，我们使用支持向量回归（SVR），核心回归（KR）和K最近邻（KNN）等非参数技术和线性回归（LR）（这是参数化技术）对模型进行训练。表1显示了所有应用程序的训练时间，训练和测试错误，以及这些技术下的平均响应时间建模。我们使用70-30％的训练和测试来分析观察结果（关于我们的实验设置，请参见第4节）。尽管除了LR以外，所有的技术都具有较低的建模误差，但SVR和KR需要大量的训练时间，因为两者都需要交叉验证来设置模型参数。 KNN可以快速训练，但是由于它将整个训练数据保存在内存中，开销非常高。神经网络错误率低，训练时间适中，开销低。因此，我们为MLscale的性能建模组件使用神经网络。请注意，我们考虑的其他ML技术在特定情况下仍然有用。例如，SVR和KR可以用于较长训练时间可接受的情况，如果有足够的能力将整个训练数据保存在记忆中，则可以利用KNN。<b>这里我很纳闷，一个用来做回归预测，一个用来进行聚类分析，二者如何实现一样的目标的。</b> <br/>
在实际的操作中，我们是要通过模型对于已经调整（scaling）后的节点进行响应时间的预测，这就有一个问题是，我们的模型是根据没有进行过调整的节点的数据进行训练的，那么对于调整过节点就理论上是不能够准确预测出来响应时间以及其他我们想要的数据的。为了解决这个问题，作者提出一种转换方案：<br/>
<code>m′ =c0 +c1·m·w/(w+k)+c2·m·k/(w+k)</code><br/>
其中，w为节点原有值，k为调整数目，m和m‘分别对应调整前后某一性能值（比如cpu平均利用率、每秒数据量等），而c0～c2是通过学习训练出来的的，其中c0表示没有运行任务的时候的空耗，比如在处理器自我包含的若干中断和上下文切换，而c1表现的是节点扩展带来的性能值的理论上变化，c2表现的是在进行扩展的时候带来的一些实际上的性能损耗<b>（学习什么？如何训练？）</b>，这样就能够比较好地预估出节点调整后的性能值，从而方便模型进行正确的预测。<br/>
为了执行自动缩放，我们首先利用度量预测器来预测提出的缩放操作的缩放后度量标准，并将这些缩放后的度量标准用作性能模型的输入来预测提议的缩放后的响应时间。 这使得我们可以通过评估当前配置周围的缩放选项（方程（2）中的w）来确定维持低于SLA目标的响应时间所需的最小缩放比例（方程式（2）中的k）。 请注意，k可以大于1，从而允许进行任意的配置更改。 我们在第5节中展示，MLscale经常为了响应负载的巨大变化而同时添加/去除多个节点。<br/>
最后，我们注意到，基础的MLscale模型可以很容易地进行再培训，以适应工作量的变化。 这对于实时更新的工作负载（例如现有网页的较新版本）或具有不同资源消耗阶段的工作负载很有用。<br/>
有关节点调整后参数调整的问题：使用单一的回归方程能够有效处理不同的特征值的变化，但是首先回归方程中回归参数的值是基于先验经验的，并且回归的具体方式文中并没有给出详细方法，只是说使用的训练集中节点调整前后性能值的变化组成的子集回归分析得到的。这种情况适用于上线时刻要求严格以及性能好的服务集群中，对于性能差的自主平台，虽然通过神经网络会在学习性能值转换模型上产生资源和时间的消耗，但是却能够相对准确反映出性能值变化规律（这个作者也提到了，在误差上神经网络要好），因此我想是否可以通过聚类分析区分出不同节点的实际性能（实际上先验或许更加靠谱，但聚类能够动态准确找出这些机器性能的变化），然后采用回归方程或者是基于神经网络学习的方式进行性能值的转化。<br/>
最后作者也提到，模型并不是一成不变的，是需要在某些时间段内重新训练的。而且为了更好找出最优调整方案，作者也建议考虑加入CPI（指令执行周期）等更加底层的具体的参数来训练模型。也体现出该方案的可拓展性和潜力。